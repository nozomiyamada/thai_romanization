{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from IPython.display import Image, display_png\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHORT_VOWELS = \"aivueyoxz\"\n",
    "LONG_VOWELS =  \"AIVUEYOXZ\"\n",
    "DIPHTHONGS = \"JWR\"\n",
    "VOWELS = SHORT_VOWELS + LONG_VOWELS + DIPHTHONGS\n",
    "ONSETS = [\"br\",\"bl\",\"pr\",\"pl\",\"Pr\",\"Pl\",\"fr\",\"fl\",\"dr\",\"tr\",\"Tr\",\"kr\",\"kl\",\"kw\",\"Kr\",\"Kl\",\"Kw\"] + \\\n",
    "    [\"b\",\"p\",\"P\",\"m\",\"f\",\"d\",\"t\",\"T\",\"n\",\"s\",\"r\",\"l\",\"c\",\"C\",\"k\",\"K\",\"N\",\"w\",\"j\",\"h\",\"?\"]\n",
    "CODAS = [\"p\",\"m\",\"f\",\"t\",\"d\",\"n\",\"s\",\"l\",\"c\",\"k\",\"N\",\"w\",\"j\",\"?\",\"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>^กก$</td>\n",
       "      <td>kok2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>^กกกอด$</td>\n",
       "      <td>kok2 kXt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>^กกช้าง$</td>\n",
       "      <td>kok2 CAN4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>^กกธูป$</td>\n",
       "      <td>kok2 TUp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>^กกหู$</td>\n",
       "      <td>kok2 hU-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31478</th>\n",
       "      <td>^ไฮโล$</td>\n",
       "      <td>haj1 lo-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31479</th>\n",
       "      <td>^ไฮไดรด์$</td>\n",
       "      <td>haj1 daj1 ra-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31480</th>\n",
       "      <td>^ไฮไฟ$</td>\n",
       "      <td>haj1 faj1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31481</th>\n",
       "      <td>^ไฮไลต์$</td>\n",
       "      <td>haj1 laj1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31482</th>\n",
       "      <td>^ไฮไลท์$</td>\n",
       "      <td>haj1 laj1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31483 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               g               p\n",
       "0           ^กก$            kok2\n",
       "1        ^กกกอด$       kok2 kXt2\n",
       "2       ^กกช้าง$       kok2 CAN4\n",
       "3        ^กกธูป$       kok2 TUp3\n",
       "4         ^กกหู$       kok2 hU-5\n",
       "...          ...             ...\n",
       "31478     ^ไฮโล$       haj1 lo-1\n",
       "31479  ^ไฮไดรด์$  haj1 daj1 ra-4\n",
       "31480     ^ไฮไฟ$       haj1 faj1\n",
       "31481   ^ไฮไลต์$       haj1 laj1\n",
       "31482   ^ไฮไลท์$       haj1 laj1\n",
       "\n",
       "[31483 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/thai2phone.csv', names=['g','p'])\n",
    "data = data[~data.g.str.contains('\\.')] # exclude abbreviation\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data['g'] = data.g.apply(lambda x: '^'+x+'$')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syl_split(syl):\n",
    "    tone = syl[-1] # prA-1 -> 1\n",
    "    coda = syl[-2] # prA-1 -> -\n",
    "    vowel = syl[-3] # prA-1 -> A\n",
    "    onset = syl[:-3] # # prA-1 -> pr\n",
    "    return onset, vowel, coda, int(tone)\n",
    "\n",
    "def make_output(phon, n=0): # n: onset, vowel, coda, tone\n",
    "    syls = phon.split()\n",
    "    splitted = [syl_split(syl)[n] for syl in syls]\n",
    "    if n==0:\n",
    "        return [onset2id[x] for x in splitted]\n",
    "    elif n==1:\n",
    "        return [vowel2id[x] for x in splitted]\n",
    "    elif n==2:\n",
    "        return [coda2id[x] for x in splitted]\n",
    "    elif n==3:\n",
    "        return splitted\n",
    "\n",
    "thai2id = {'<PAD>':0, '^':1, '$':2, ' ':3}\n",
    "for i in range(3585, 3674): # ก=3585->4, ๙=3673\n",
    "    thai2id[chr(i)] = i - 3581\n",
    "id2thai = {v:k for k,v in thai2id.items()}\n",
    "\n",
    "onset2id = {'<UNK>':-1,'<PAD>':0,'<SOS>':1,'<EOS>':2}\n",
    "for c in ONSETS:\n",
    "    onset2id[c] = max(onset2id.values()) + 1\n",
    "id2onset = {v:k for k,v in onset2id.items()}\n",
    "\n",
    "coda2id = {'<UNK>':-1,'<PAD>':0,'<SOS>':1,'<EOS>':2}\n",
    "for c in CODAS:\n",
    "    coda2id[c] = max(coda2id.values()) + 1\n",
    "id2coda = {v:k for k,v in coda2id.items()}\n",
    "\n",
    "vowel2id = {'<UNK>':-1,'<PAD>':0,'<SOS>':1,'<EOS>':2}\n",
    "for c in VOWELS:\n",
    "    vowel2id[c] = max(vowel2id.values()) + 1\n",
    "id2vowel = {v:k for k,v in vowel2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ka-2 ra-4 nI-1 cam1 pen1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[17, 17, 17, 4, 8]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.p[100])\n",
    "make_output(data.p[100], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# max len of input character length\n",
    "print(max(map(len, data.g)))\n",
    "\n",
    "# max len of output syllable length\n",
    "print(max([len(x.split(\" \")) for x in data.p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation ##\n",
    "for phon in data.p:\n",
    "    try:\n",
    "        make_output(phon, n=3)\n",
    "    except:\n",
    "        print(phon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = [[thai2id[c] for c in word] for word in data.g]\n",
    "input_seq = pad_sequences(input_seq, padding='post', maxlen=55, value=0)\n",
    "\n",
    "output0 = [[1]+make_output(phon, n=0) for phon in data.p] # onset\n",
    "output1 = [[1]+make_output(phon, n=1) for phon in data.p] # vowel\n",
    "output2 = [[1]+make_output(phon, n=2) for phon in data.p] # coda\n",
    "output3 = [[-1]+make_output(phon, n=3) for phon in data.p] # tone\n",
    "output4 = [[0]*(len(seq)-1)+[1] for seq in output0] # end condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 34, 30, 28, 32, 21]\n",
      "[1, 3, 3, 13, 3, 7]\n",
      "[1, 17, 17, 17, 4, 8]\n",
      "[-1, 2, 4, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "i = 100\n",
    "\n",
    "print(output0[i])\n",
    "print(output1[i])\n",
    "print(output2[i])\n",
    "print(output3[i])\n",
    "print(output4[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 34 30 28 32 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 1  3  3 13  3  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 1 17 17 17  4  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[-1  2  4  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "### padding ###\n",
    "output0 = pad_sequences(output0, padding='post', maxlen=20, value=0)\n",
    "output1 = pad_sequences(output1, padding='post', maxlen=20, value=0)\n",
    "output2 = pad_sequences(output2, padding='post', maxlen=20, value=0)\n",
    "output3 = pad_sequences(output3, padding='post', maxlen=20, value=0)\n",
    "output4 = pad_sequences(output4, padding='post', maxlen=20, value=1)\n",
    "\n",
    "i = 100\n",
    "\n",
    "print(output0[i])\n",
    "print(output1[i])\n",
    "print(output2[i])\n",
    "print(output3[i])\n",
    "print(output4[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "output0 = to_categorical(output0, num_classes=len(onset2id))\n",
    "output1 = to_categorical(output1, num_classes=len(vowel2id))\n",
    "output2 = to_categorical(output2, num_classes=len(coda2id))\n",
    "output3 = to_categorical(output3, num_classes=7)\n",
    "output4 = to_categorical(output4, num_classes=2)\n",
    "\n",
    "i = 100\n",
    "print(output3[i])\n",
    "print(output4[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = layers.Input(batch_size=None, shape=(data.input_maxlen,), name='Enc_Input')\n",
    "embedding1 = layers.Embedding(input_dim = data.input_vocab, # num of vocab = num of ID dict\n",
    "                                    input_length = data.input_maxlen,\n",
    "                                    output_dim = emb_dim,\n",
    "                                    mask_zero = True,\n",
    "                                    name = 'Enc_Embedding')\n",
    "lstm = layers.Bidirectional(layers.LSTM(lstm_dim,\n",
    "                                        return_sequences=return_seq, # use only final output when w/o attention -> return (batch, lstm_dim)\n",
    "                                        return_state=True,\n",
    "                                        recurrent_dropout=lstm_dropout,\n",
    "                                        name='Enc_LSTM'), name='BiDir') # return: output, h1, c1, h2, c2\n",
    "concat_h = layers.Concatenate(name='Concat_h') # concatnate bidirectional output of state h \n",
    "concat_c = layers.Concatenate(name='Concat_c') # concatnate bidirectional output of state c\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.input\n",
    "        x = self.embedding(x)\n",
    "        x, h1, c1, h2, c2 = self.lstm(x)\n",
    "        h = self.concat_h([h1, h2])\n",
    "        c = self.concat_c([c1, c2])\n",
    "        return x, h, c\n",
    "\n",
    "    def build(self):\n",
    "        x, h, c = self()\n",
    "        model = keras.models.Model(inputs=self.input, outputs=[x,h,c])\n",
    "        return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
